{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05. Model Deployment and Inference\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Deploying a model for Batch Inference using SageMaker Batch Transform\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/sagemaker-course/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Change into the notebooks directory.\n",
    "%cd /root/sagemaker-course/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts will be written to s3://sagemaker-course-20200812/churn\n",
      "Role ARN: arn:aws:iam::209970524256:role/service-role/AmazonSageMaker-ExecutionRole-20200618T144956\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# S3 bucket information\n",
    "BUCKET = 'sagemaker-course-20200812'\n",
    "PREFIX = 'churn'\n",
    "LOCAL_DATA_DIRECTORY = f'../data/{PREFIX}'\n",
    "print(f\"Artifacts will be written to s3://{BUCKET}/{PREFIX}\")\n",
    "\n",
    "# Session variables we'll use throughout the notebook\n",
    "sagemaker_session = sagemaker.Session()\n",
    "boto_session = sagemaker_session.boto_session\n",
    "sagemaker_client = boto_session.client('sagemaker')\n",
    "role = get_execution_role()\n",
    "print(f'Role ARN: {role}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Prepare Input Data\n",
    "\n",
    "\n",
    "```\n",
    "An example of input file content:\n",
    "                Record1-Attribute1, Record1-Attribute2, Record1-Attribute3, ..., Record1-AttributeM\n",
    "                Record2-Attribute1, Record2-Attribute2, Record2-Attribute3, ..., Record2-AttributeM\n",
    "                Record3-Attribute1, Record3-Attribute2, Record3-Attribute3, ..., Record3-AttributeM\n",
    "                ...\n",
    "                RecordN-Attribute1, RecordN-Attribute2, RecordN-Attribute3, ..., RecordN-AttributeM\n",
    "```         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186,0,137.8,97,187.7,118,146.4,85,8.7,6,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0\n",
      "132,25,113.2,96,269.9,107,229.1,87,7.1,7,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1\n",
      "112,17,183.2,95,252.8,125,156.7,95,9.7,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1\n",
      "91,24,93.5,112,183.4,128,240.7,133,9.9,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1\n",
      "22,0,110.3,107,166.5,93,202.3,96,9.5,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../data/churn/test-batch.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-course-20200812/churn/test-batch.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_file_path = '../data/churn/test-batch.csv'\n",
    "\n",
    "inference_data = sagemaker_session.upload_data(\n",
    "    local_file_path,\n",
    "    bucket=BUCKET,\n",
    "    key_prefix=PREFIX)\n",
    "\n",
    "inference_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Initialize a `Tranformer` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the `sagemaker.model.Model` [API reference](https://sagemaker.readthedocs.io/en/stable/model.html) for more details.\n",
    "from sagemaker import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = 's3://sagemaker-course-20200812/churn/builtin-xgboost-2020-08-12-12-05-52-988/output/model.tar.gz'\n",
    "image_uri = '257758044811.dkr.ecr.us-east-2.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3'\n",
    "\n",
    "churn_model = model.Model(model_data=model_data,\n",
    "                          image_uri=image_uri,\n",
    "                          role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the `sagemaker.transformer.Transformer` [API reference](https://sagemaker.readthedocs.io/en/stable/transformer.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_transformer = churn_model.transformer(instance_count=1,\n",
    "                                            instance_type='ml.m4.xlarge',\n",
    "                                            strategy='MultiRecord',\n",
    "                                            assemble_with='Line',\n",
    "                                            output_path=f's3://{BUCKET}/{PREFIX}/transform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Run Transform Job "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: This takes about 3-5 minutes to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34m[2020-08-14:12:13:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-08-14:12:13:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-08-14:12:13:35:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020/08/14 12:13:35 [crit] 18#18: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Aug/2020:12:13:35 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/08/14 12:13:35 [crit] 18#18: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Aug/2020:12:13:35 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-08-14 12:13:35 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2020-08-14 12:13:35 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[34m[2020-08-14 12:13:35 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-08-14 12:13:35 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2020-08-14 12:13:35 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2020-08-14 12:13:35 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2020-08-14 12:13:35 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2020-08-14:12:13:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Aug/2020:12:13:37 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-08-14:12:13:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Aug/2020:12:13:37 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-08-14:12:13:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-08-14:12:13:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Aug/2020:12:13:37 +0000] \"POST /invocations HTTP/1.1\" 200 6793 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[32m2020-08-14T12:13:37.688:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start a transform job and wait for it to finish\n",
    "churn_transformer.transform(data=inference_data,\n",
    "                            content_type='text/csv',\n",
    "                            split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-course-20200812/churn/transform'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '844AA9BD7A7B3991',\n",
       "  'HostId': '2iE4LSFOdVoelMTALCHlL8R7ywSkaXlMfLHuFeze07mg0ijGVCScRYbwfGJC6MHAnBGzvJ+ZcFI=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '2iE4LSFOdVoelMTALCHlL8R7ywSkaXlMfLHuFeze07mg0ijGVCScRYbwfGJC6MHAnBGzvJ+ZcFI=',\n",
       "   'x-amz-request-id': '844AA9BD7A7B3991',\n",
       "   'date': 'Fri, 14 Aug 2020 12:14:20 GMT',\n",
       "   'x-amz-bucket-region': 'us-east-2',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Marker': '',\n",
       " 'Contents': [{'Key': 'churn/transform/test-batch.csv.out',\n",
       "   'LastModified': datetime.datetime(2020, 8, 14, 12, 13, 38, tzinfo=tzlocal()),\n",
       "   'ETag': '\"d2ef9f21be4c84bc9a0500de78e1362b\"',\n",
       "   'Size': 6793,\n",
       "   'StorageClass': 'STANDARD'}],\n",
       " 'Name': 'sagemaker-course-20200812',\n",
       " 'Prefix': 'churn/transform',\n",
       " 'MaxKeys': 1000,\n",
       " 'EncodingType': 'url'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List files in S3 bucket\n",
    "s3_client = boto_session.client('s3')\n",
    "s3_client.list_objects(Bucket = BUCKET, Prefix = f'{PREFIX}/transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the output data from S3 to local filesystem\n",
    "s3_client.download_file(\n",
    "    Bucket=BUCKET,\n",
    "    Key=f'{PREFIX}/transform/test-batch.csv.out',\n",
    "    Filename=f'{LOCAL_DATA_DIRECTORY}/test-batch.csv.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010853796266019344\n",
      "0.005068291909992695\n",
      "0.008791499771177769\n",
      "0.16663919389247894\n",
      "0.004287515766918659\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../data/churn/test-batch.csv.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Creating a SageMaker Endpoint for Online Inference\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the `sagemaker.sklearn.SKLearnModel` [API reference](https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html#sagemaker.sklearn.model.SKLearnModel) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = 's3://sagemaker-course-20200812/churn/custom-code-sklearn-2020-08-12-12-16-44-914/output/model.tar.gz'\n",
    "\n",
    "sklearn_model = sklearn.SKLearnModel(framework_version='0.20.0',\n",
    "                                     model_data=model_data, \n",
    "                                     role=role,\n",
    "                                     entry_point='../scripts/sklearn/sklearn_rf.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the `sagemaker.predictor.RealTimePredictor` [API reference](https://sagemaker.readthedocs.io/en/stable/predictors.html) for more details.\n",
    "\n",
    "**NOTE: This takes about 6-8 minutes to return.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "sklearn_predictor = sklearn_model.deploy(initial_instance_count=1,\n",
    "                                         instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sagemaker.sklearn.model.SKLearnPredictor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sklearn_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>137.8</td>\n",
       "      <td>97</td>\n",
       "      <td>187.7</td>\n",
       "      <td>118</td>\n",
       "      <td>146.4</td>\n",
       "      <td>85</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>25</td>\n",
       "      <td>113.2</td>\n",
       "      <td>96</td>\n",
       "      <td>269.9</td>\n",
       "      <td>107</td>\n",
       "      <td>229.1</td>\n",
       "      <td>87</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>17</td>\n",
       "      <td>183.2</td>\n",
       "      <td>95</td>\n",
       "      <td>252.8</td>\n",
       "      <td>125</td>\n",
       "      <td>156.7</td>\n",
       "      <td>95</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>93.5</td>\n",
       "      <td>112</td>\n",
       "      <td>183.4</td>\n",
       "      <td>128</td>\n",
       "      <td>240.7</td>\n",
       "      <td>133</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>107</td>\n",
       "      <td>166.5</td>\n",
       "      <td>93</td>\n",
       "      <td>202.3</td>\n",
       "      <td>96</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2      3    4      5    6      7    8    9   10  ...  60  61  62  63  \\\n",
       "0  186   0  137.8   97  187.7  118  146.4   85  8.7   6  ...   0   0   0   0   \n",
       "1  132  25  113.2   96  269.9  107  229.1   87  7.1   7  ...   0   0   0   0   \n",
       "2  112  17  183.2   95  252.8  125  156.7   95  9.7   3  ...   0   0   0   0   \n",
       "3   91  24   93.5  112  183.4  128  240.7  133  9.9   3  ...   0   0   0   0   \n",
       "4   22   0  110.3  107  166.5   93  202.3   96  9.5   5  ...   0   0   0   1   \n",
       "\n",
       "   64  65  66  67  68  69  \n",
       "0   0   1   1   0   1   0  \n",
       "1   1   0   1   0   0   1  \n",
       "2   1   0   1   0   0   1  \n",
       "3   0   1   0   1   0   1  \n",
       "4   0   0   1   0   1   0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{LOCAL_DATA_DIRECTORY}/test-dataset.csv', header=None)\n",
    "\n",
    "# Remove first column which contains labels\n",
    "X = df.drop(labels=0, axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "preds = sklearn_predictor.predict(X)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Configure Autoscaling for a Hosted Endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To configure autoscaling for a model using the console**:\n",
    "\n",
    "1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\n",
    "2. In the navigation pane, choose **Endpoints**.\n",
    "3. Choose the endpoint that you want to configure.\n",
    "4. Under the **Endpoint runtime settings** heading, select the radio button corresponding to the model variant that you want to configure and click **Configure autoscaling**. The **Configure variant automatic scaling** page appears.\n",
    "5. The **Variant automatic scaling** section lets us configure the min/max number of instances.\n",
    "    * For **Minimum instance count**, type the minimum number of instances that you want the scaling policy to maintain. At least 1 instance is required.\n",
    "    * For **Maximum instance count**, type the maximum number of instances that you want the scaling policy to maintain.\n",
    "6. The **Built-in scaling policy** section lets us configure the conditions under which to scale the instances.\n",
    "    * For the **Target value**, type the average number of invocations per instance per minute for the model. To determine this value, follow the guidelines in Load testing. Application Auto Scaling adds or removes instances to keep the metric close to the value that you specify.\n",
    "    * For **Scale-in cool down** and **Scale-out cool down** type the number seconds for each cool down period. Assuming that the order in the list is based on either most important to less important of first applied to last applied.\n",
    "    * Select **Disable scale in** to prevent the scaling policy from deleting variant instances if you want to ensure that your variant scales out to address increased traffic, but are not concerned with removing instances to reduce costs when traffic decreases. Scale-out activities are always enabled so that the scaling policy can create endpoint instances as needed.\n",
    "7. Choose **Save**.\n",
    "\n",
    "More details, including how to define a custom scaling policy, can be found in the [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling-add-console.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
